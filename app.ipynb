{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Function to get real-time sensor data from the testbed\n",
    "\n",
    "\n",
    "def get_sensor_data(node_id):\n",
    "    # Replace this function with actual code to collect data from the sensor node\n",
    "    # This could involve querying a database, an API call, or reading directly from hardware\n",
    "    # For demonstration, we return a dictionary of random values\n",
    "    return {\n",
    "        'Packet_Rate': np.random.normal(50, 10),\n",
    "        'Packet_Drop_Rate': np.random.normal(2, 0.5),\n",
    "        'Packet_Duplication_Rate': np.random.normal(1, 0.2),\n",
    "        'Data_Throughput': np.random.normal(1000, 200),\n",
    "        'Signal_Strength': np.random.randint(0, 100),\n",
    "        'SNR': np.random.normal(20, 5),\n",
    "        'Battery_Level': np.random.randint(0, 100),\n",
    "        'Energy_Consumption_Rate': np.random.normal(5, 1),\n",
    "        'Number_of_Neighbors': np.random.randint(0, 10),\n",
    "        'Route_Request_Frequency': np.random.normal(1, 0.2),\n",
    "        'Route_Reply_Frequency': np.random.normal(1, 0.2),\n",
    "        'Data_Transmission_Frequency': np.random.normal(100, 20),\n",
    "        'Data_Reception_Frequency': np.random.normal(100, 20),\n",
    "        'Error_Rate': np.random.normal(0.1, 0.02),\n",
    "        'CPU_Usage': np.random.randint(0, 100),\n",
    "        'Memory_Usage': np.random.randint(0, 100),\n",
    "        'Bandwidth': np.random.normal(100, 20),\n",
    "        'Is_Malicious': np.random.choice([0, 1], p=[0.95, 0.05])\n",
    "    }\n",
    "\n",
    "\n",
    "# Number of samples (e.g., number of sensor nodes)\n",
    "n_samples = 100\n",
    "\n",
    "# Initialize a list to store data\n",
    "data_list = []\n",
    "\n",
    "for i in range(1, n_samples + 1):\n",
    "    # Get current timestamp\n",
    "    current_timestamp = datetime.now().strftime('%d-%m-%y %H:%M:%S')\n",
    "\n",
    "    # Get IP address (you should replace this with the actual IP address of the sensor node)\n",
    "    ip_address = f\"192.168.{np.random.randint(0, 255)}.{np.random.randint(0, 255)}\"\n",
    "\n",
    "    # Get real-time data from sensor node with ID=i\n",
    "    sensor_data = get_sensor_data(i)\n",
    "\n",
    "    # Append to data list\n",
    "    data_list.append({\n",
    "        'Node_ID': i,\n",
    "        'Timestamp': current_timestamp,\n",
    "        'IP_Address': ip_address,\n",
    "        **sensor_data  # Unpack sensor data dictionary\n",
    "    })\n",
    "\n",
    "    # Simulate a delay between each data collection (optional)\n",
    "    time.sleep(0.1)  # 100ms delay\n",
    "\n",
    "# Convert data list to DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'RealTime_SensorNetGuard_A_Dataset_for_Identifying_Malicious_Sensor_Nodes.csv'\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 191ms/step - loss: 0.6998 - accuracy: 0.0000e+00 - val_loss: 0.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6930 - accuracy: 0.0139 - val_loss: 0.6844 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6937 - accuracy: 0.0139 - val_loss: 0.6841 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6924 - accuracy: 0.0139 - val_loss: 0.6850 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6907 - accuracy: 0.0139 - val_loss: 0.6866 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6865 - accuracy: 0.0139 - val_loss: 0.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6915 - accuracy: 0.0278 - val_loss: 0.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6882 - accuracy: 0.0139 - val_loss: 0.6883 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6899 - accuracy: 0.0000e+00 - val_loss: 0.6904 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6891 - accuracy: 0.0278 - val_loss: 0.6925 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6925 - accuracy: 0.0000e+00\n",
      "Loss: 0.6925227046012878, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load your CSV data into a DataFrame\n",
    "df = pd.read_csv(\n",
    "    'RealTime_SensorNetGuard_A_Dataset_for_Identifying_Malicious_Sensor_Nodes.csv')\n",
    "\n",
    "# Prepare data as sequences for LSTM\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequence = data[i:i + seq_length]\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "# Define sequence length (number of time steps)\n",
    "seq_length = 10  # Adjust as needed based on your data and model\n",
    "\n",
    "# Convert DataFrame to numpy array and normalize data\n",
    "data_array = df.drop(['Node_ID', 'Timestamp', 'IP_Address'], axis=1).values\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_array)\n",
    "\n",
    "# Create sequences\n",
    "sequences = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1][:, 0]  # Extract Is_Malicious column as target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and compile LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
